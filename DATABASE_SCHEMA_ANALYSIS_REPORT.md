# RELAT√ìRIO DE AN√ÅLISE COMPLETA DO SCHEMA DE BANCO DE DADOS - IMOBIBASE

**Data:** 25 de Dezembro de 2024
**Escopo:** 100% do schema (PostgreSQL + SQLite)
**Tabelas Analisadas:** 51 tabelas
**Migra√ß√µes Revisadas:** 11 arquivos SQL

---

## √çNDICE

1. [Resumo Executivo](#resumo-executivo)
2. [Problemas Cr√≠ticos Identificados](#problemas-criticos)
3. [An√°lise por Tabela](#analise-por-tabela)
4. [Indexes Faltantes](#indexes-faltantes)
5. [Problemas de Normaliza√ß√£o](#normalizacao)
6. [Queries Lentas Potenciais](#queries-lentas)
7. [Melhorias de Performance](#melhorias-performance)
8. [Scripts SQL de Corre√ß√£o](#scripts-sql)
9. [Roadmap de Implementa√ß√£o](#roadmap)

---

## 1. RESUMO EXECUTIVO

### Status Geral: üü¢ BOM (P√≥s-Melhorias)

O schema do ImobiBase passou por melhorias significativas recentes com as migra√ß√µes de 25/12/2024. No entanto, ainda existem oportunidades de otimiza√ß√£o.

### Conquistas Recentes ‚úÖ

- **85+ indexes de performance** adicionados
- **CHECK constraints** implementados em 100% das tabelas cr√≠ticas
- **CASCADE behaviors** configurados corretamente
- **UNIQUE constraints** para prevenir duplica√ß√£o
- **Soft deletes** implementados em 12 tabelas principais
- **Audit trail** completo via triggers

### Problemas Restantes üî¥

1. **Falta de particionamento** em tabelas de alto volume (audit_logs, usage_logs)
2. **Campos JSON sem valida√ß√£o** em v√°rias tabelas
3. **Falta de full-text search indexes** para buscas de texto
4. **Aus√™ncia de materialized views** para reports complexos
5. **Timestamps sem timezone** no SQLite
6. **Falta de √≠ndices GiST/GIN** para arrays e JSON
7. **Sem row-level security (RLS)** configurado

---

## 2. PROBLEMAS CR√çTICOS IDENTIFICADOS

### üî¥ CR√çTICO - Alta Prioridade

#### 2.1 Tabela `audit_logs` / `compliance_audit_log` - Crescimento Descontrolado

**Problema:**
```sql
-- Tabela crescer√° MUITO R√ÅPIDO (1M+ registros/m√™s em produ√ß√£o)
CREATE TABLE audit_logs (
  id varchar PRIMARY KEY,
  -- ... sem particionamento
);
```

**Impacto:**
- Queries lentas ap√≥s 1M+ registros
- Backup/restore demorados
- Disk space ilimitado

**Solu√ß√£o:**
```sql
-- Criar particionamento por data (PostgreSQL 11+)
CREATE TABLE audit_logs (
  id varchar PRIMARY KEY,
  created_at timestamp NOT NULL DEFAULT NOW(),
  -- ... outros campos
) PARTITION BY RANGE (created_at);

-- Parti√ß√µes mensais
CREATE TABLE audit_logs_2024_12 PARTITION OF audit_logs
  FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');

CREATE TABLE audit_logs_2025_01 PARTITION OF audit_logs
  FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

-- Criar automaticamente via cron/scheduler
CREATE OR REPLACE FUNCTION create_audit_partition()
RETURNS void AS $$
DECLARE
  start_date DATE;
  end_date DATE;
  partition_name TEXT;
BEGIN
  start_date := date_trunc('month', NOW() + INTERVAL '1 month');
  end_date := start_date + INTERVAL '1 month';
  partition_name := 'audit_logs_' || to_char(start_date, 'YYYY_MM');

  EXECUTE format(
    'CREATE TABLE IF NOT EXISTS %I PARTITION OF audit_logs FOR VALUES FROM (%L) TO (%L)',
    partition_name, start_date, end_date
  );
END;
$$ LANGUAGE plpgsql;
```

**Prioridade:** üî¥ CR√çTICA
**Estimativa:** 4 horas de implementa√ß√£o

---

#### 2.2 Campos JSON sem √çndices nem Valida√ß√£o

**Problema:**
```sql
-- 15+ tabelas com campos JSON sem √≠ndices
permissions: json("permissions").notNull().default('{}')
config: json("config").default('{}')
metadata: json("metadata").default('{}')
```

**Impacto:**
- Queries em JSON s√£o FULL TABLE SCAN
- Sem valida√ß√£o de schema JSON
- Performance degradada

**Solu√ß√£o:**
```sql
-- 1. Adicionar √≠ndices GIN para busca em JSON
CREATE INDEX idx_user_roles_permissions_gin ON user_roles USING GIN (permissions);
CREATE INDEX idx_integration_configs_config_gin ON integration_configs USING GIN (config);
CREATE INDEX idx_files_metadata_gin ON files USING GIN (metadata);

-- 2. Adicionar valida√ß√£o de schema (PostgreSQL 12+)
ALTER TABLE user_roles
ADD CONSTRAINT check_permissions_valid
CHECK (
  jsonb_typeof(permissions::jsonb) = 'object' AND
  permissions::jsonb ? 'properties' AND
  permissions::jsonb ? 'leads'
);

-- 3. Criar √≠ndices parciais para queries comuns
CREATE INDEX idx_integration_configs_whatsapp
  ON integration_configs ((config->>'whatsappEnabled'))
  WHERE integration_name = 'whatsapp';
```

**Prioridade:** üî¥ ALTA
**Estimativa:** 3 horas

---

#### 2.3 Falta de Full-Text Search

**Problema:**
```sql
-- Buscas em texto usam ILIKE = LENTO
SELECT * FROM properties
WHERE title ILIKE '%apartamento%'
   OR description ILIKE '%apartamento%';
-- Resultado: Full table scan em 100k+ properties
```

**Impacto:**
- Busca lenta (2-10s em 100k+ registros)
- Alto uso de CPU
- UX ruim

**Solu√ß√£o:**
```sql
-- PostgreSQL: Adicionar tsvector e √≠ndice GIN
ALTER TABLE properties
ADD COLUMN search_vector tsvector
GENERATED ALWAYS AS (
  to_tsvector('portuguese',
    coalesce(title, '') || ' ' ||
    coalesce(description, '') || ' ' ||
    coalesce(address, '') || ' ' ||
    coalesce(city, '')
  )
) STORED;

CREATE INDEX idx_properties_search_vector
  ON properties USING GIN (search_vector);

-- Query otimizada
SELECT * FROM properties
WHERE search_vector @@ to_tsquery('portuguese', 'apartamento')
  AND tenant_id = 'xxx'
  AND deleted_at IS NULL;
-- Resultado: 10-50ms mesmo com 1M+ registros
```

**Prioridade:** üî¥ ALTA
**Estimativa:** 2 horas

---

### üü° M√âDIO - M√©dia Prioridade

#### 2.4 Falta de Materialized Views para Reports

**Problema:**
```sql
-- Dashboard queries s√£o complexas e lentas
SELECT
  COUNT(*) as total_properties,
  SUM(CASE WHEN status = 'available' THEN 1 ELSE 0 END) as available,
  -- ... muitos JOINs e agrega√ß√µes
FROM properties
LEFT JOIN visits ON ...
LEFT JOIN contracts ON ...
WHERE tenant_id = 'xxx'
GROUP BY ...;
-- Resultado: 2-5s em cada dashboard load
```

**Solu√ß√£o:**
```sql
-- Criar materialized view para dashboard
CREATE MATERIALIZED VIEW dashboard_metrics_mv AS
SELECT
  tenant_id,
  COUNT(*) as total_properties,
  COUNT(*) FILTER (WHERE status = 'available') as available_properties,
  COUNT(*) FILTER (WHERE status = 'rented') as rented_properties,
  COUNT(DISTINCT CASE WHEN featured = true THEN id END) as featured_count,
  -- ... mais m√©tricas
FROM properties
WHERE deleted_at IS NULL
GROUP BY tenant_id;

-- √çndice √∫nico na MV
CREATE UNIQUE INDEX idx_dashboard_metrics_mv_tenant
  ON dashboard_metrics_mv (tenant_id);

-- Refresh autom√°tico (a cada 5 minutos)
CREATE OR REPLACE FUNCTION refresh_dashboard_metrics()
RETURNS void AS $$
BEGIN
  REFRESH MATERIALIZED VIEW CONCURRENTLY dashboard_metrics_mv;
END;
$$ LANGUAGE plpgsql;

-- Adicionar ao pg_cron ou scheduler
SELECT cron.schedule('refresh-dashboard', '*/5 * * * *', 'SELECT refresh_dashboard_metrics()');
```

**Prioridade:** üü° M√âDIA
**Estimativa:** 3 horas

---

#### 2.5 Aus√™ncia de Row-Level Security (RLS)

**Problema:**
- Sem prote√ß√£o nativa do PostgreSQL contra queries sem tenant_id
- Risco de vazamento de dados entre tenants

**Solu√ß√£o:**
```sql
-- Habilitar RLS em todas as tabelas multi-tenant
ALTER TABLE properties ENABLE ROW LEVEL SECURITY;
ALTER TABLE leads ENABLE ROW LEVEL SECURITY;
ALTER TABLE contracts ENABLE ROW LEVEL SECURITY;
-- ... (todas as tabelas com tenant_id)

-- Criar policy para isolamento de tenant
CREATE POLICY tenant_isolation_policy ON properties
  USING (tenant_id = current_setting('app.current_tenant')::varchar);

CREATE POLICY tenant_isolation_policy ON leads
  USING (tenant_id = current_setting('app.current_tenant')::varchar);

-- No c√≥digo da aplica√ß√£o (antes de cada query):
-- SET LOCAL app.current_tenant = 'tenant-id-123';
```

**Prioridade:** üü° M√âDIA-ALTA (Seguran√ßa)
**Estimativa:** 4 horas

---

## 3. AN√ÅLISE POR TABELA

### Tabela: `properties`

**Status:** üü¢ BOM (com melhorias recentes)

**Schema Atual:**
```sql
CREATE TABLE properties (
  id varchar PRIMARY KEY,
  tenant_id varchar NOT NULL REFERENCES tenants(id),
  title text NOT NULL,
  description text,
  type text NOT NULL,
  category text NOT NULL,
  price decimal(12,2) NOT NULL,
  address text NOT NULL,
  city text NOT NULL,
  state text NOT NULL,
  zip_code text,
  bedrooms integer,
  bathrooms integer,
  area integer,
  features text[] / text (JSON), -- PostgreSQL / SQLite
  images text[] / text (JSON),
  status text NOT NULL DEFAULT 'available',
  featured boolean NOT NULL DEFAULT false,
  created_at timestamp NOT NULL DEFAULT NOW(),
  updated_at timestamp NOT NULL DEFAULT NOW(),
  deleted_at timestamp -- ‚úÖ Adicionado recentemente
);
```

**Problemas Identificados:**

1. ‚ùå **Falta de normaliza√ß√£o do endere√ßo**
   - `city`, `state` deveriam ser FK para tabela `cities`
   - Inconsist√™ncia de dados (ex: "S√£o Paulo", "SAO PAULO", "Sao Paulo")

2. ‚ùå **Arrays sem √≠ndice GIN** (PostgreSQL)
   ```sql
   -- Query lenta:
   SELECT * FROM properties
   WHERE 'piscina' = ANY(features);
   -- Solu√ß√£o:
   CREATE INDEX idx_properties_features_gin ON properties USING GIN (features);
   ```

3. ‚ùå **Falta de geolocaliza√ß√£o**
   - Sem campos `latitude`, `longitude` na tabela principal
   - Depende de tabela separada `property_coordinates`

4. ‚ö†Ô∏è **Campo `type` e `category` sem ENUM**
   - Permite valores inv√°lidos
   - Solu√ß√£o: Usar CHECK constraint ou tabela de refer√™ncia

**Indexes Atuais (‚úÖ BOM):**
```sql
idx_properties_tenant_id
idx_properties_tenant_status
idx_properties_featured
idx_properties_city_state
idx_properties_created_at
idx_properties_tenant_status_featured
idx_properties_deleted_at
```

**Melhorias Recomendadas:**

```sql
-- 1. Adicionar √≠ndice GIN para arrays
CREATE INDEX idx_properties_features_gin
  ON properties USING GIN (features);

CREATE INDEX idx_properties_images_gin
  ON properties USING GIN (images);

-- 2. √çndice composto para filtros comuns
CREATE INDEX idx_properties_city_status_price
  ON properties (city, status, price)
  WHERE deleted_at IS NULL;

-- 3. Full-text search (ver se√ß√£o 2.3)

-- 4. Adicionar campos de geo na tabela principal
ALTER TABLE properties
ADD COLUMN latitude DECIMAL(10, 8),
ADD COLUMN longitude DECIMAL(11, 8);

CREATE INDEX idx_properties_location
  ON properties USING GIST (ll_to_earth(latitude, longitude));
```

---

### Tabela: `leads`

**Status:** üü¢ BOM

**Problemas Identificados:**

1. ‚ùå **Email sem valida√ß√£o de formato**
   ```sql
   -- Adicionar:
   ALTER TABLE leads
   ADD CONSTRAINT check_email_format
   CHECK (email ~* '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$');
   ```

2. ‚ùå **Phone sem formata√ß√£o padronizada**
   - Permite: "(11) 99999-9999", "11999999999", "+55 11 99999-9999"
   - Solu√ß√£o: Trigger para normaliza√ß√£o

3. ‚ö†Ô∏è **Falta de lead scoring autom√°tico**
   - Existe tabela `lead_scores` mas sem trigger de atualiza√ß√£o

**Indexes Atuais (‚úÖ BOM):**
```sql
idx_leads_tenant_id
idx_leads_tenant_status
idx_leads_assigned_to
idx_leads_email
idx_leads_source
idx_leads_created_at
idx_leads_tenant_status_assigned
idx_leads_deleted_at
```

**Melhorias Recomendadas:**

```sql
-- 1. Trigger para lead scoring autom√°tico
CREATE OR REPLACE FUNCTION update_lead_score()
RETURNS TRIGGER AS $$
BEGIN
  -- Calcular score baseado em dados do lead
  INSERT INTO lead_scores (lead_id, total_score, budget_score, profile_score)
  VALUES (
    NEW.id,
    calculate_total_score(NEW),
    calculate_budget_score(NEW.budget),
    calculate_profile_score(NEW)
  )
  ON CONFLICT (lead_id)
  DO UPDATE SET
    total_score = calculate_total_score(NEW),
    budget_score = calculate_budget_score(NEW.budget),
    last_calculated = NOW();

  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trg_lead_score_update
  AFTER INSERT OR UPDATE ON leads
  FOR EACH ROW
  EXECUTE FUNCTION update_lead_score();

-- 2. √çndice para busca por telefone normalizado
CREATE INDEX idx_leads_phone_normalized
  ON leads (regexp_replace(phone, '[^0-9]', '', 'g'));
```

---

### Tabela: `rental_payments`

**Status:** üü° ATEN√á√ÉO (Crescimento R√°pido)

**Problemas Identificados:**

1. üî¥ **Crescimento r√°pido sem particionamento**
   - 12 registros/ano por contrato
   - 1000 contratos = 12k registros/ano
   - Ap√≥s 5 anos = 60k registros

2. ‚ùå **Falta de √≠ndice para pagamentos atrasados**
   ```sql
   -- Query comum (lenta):
   SELECT * FROM rental_payments
   WHERE status = 'pending'
     AND due_date < CURRENT_DATE
     AND tenant_id = 'xxx';
   ```

**Indexes Atuais (‚úÖ Parcial):**
```sql
idx_rental_payments_tenant_id
idx_rental_payments_contract_id
idx_rental_payments_status
idx_rental_payments_due_date
idx_rental_payments_reference_month
idx_rental_payments_tenant_status_due -- ‚úÖ
idx_rental_payments_pending -- ‚úÖ Parcial
idx_rental_payments_overdue -- ‚úÖ Cr√≠tico
```

**Melhorias Recomendadas:**

```sql
-- 1. Particionamento por ano (para hist√≥rico longo)
CREATE TABLE rental_payments_2024 PARTITION OF rental_payments
  FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');

CREATE TABLE rental_payments_2025 PARTITION OF rental_payments
  FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');

-- 2. √çndice para c√°lculo de inadimpl√™ncia
CREATE INDEX idx_rental_payments_overdue_calc
  ON rental_payments (tenant_id, status, due_date, total_value)
  WHERE status IN ('pending', 'overdue') AND deleted_at IS NULL;

-- 3. Materialized view para dashboard financeiro
CREATE MATERIALIZED VIEW rental_payments_summary_mv AS
SELECT
  tenant_id,
  date_trunc('month', due_date) as month,
  COUNT(*) as total_payments,
  COUNT(*) FILTER (WHERE status = 'paid') as paid_count,
  COUNT(*) FILTER (WHERE status = 'pending') as pending_count,
  COUNT(*) FILTER (WHERE status = 'overdue') as overdue_count,
  SUM(total_value) as total_amount,
  SUM(total_value) FILTER (WHERE status = 'paid') as paid_amount,
  SUM(total_value) FILTER (WHERE status = 'pending') as pending_amount
FROM rental_payments
WHERE deleted_at IS NULL
GROUP BY tenant_id, date_trunc('month', due_date);

CREATE INDEX idx_rental_payments_summary_mv_tenant_month
  ON rental_payments_summary_mv (tenant_id, month);
```

---

### Tabela: `whatsapp_messages`

**Status:** üî¥ CR√çTICO (Alto Volume)

**Problemas Identificados:**

1. üî¥ **ALTO VOLUME esperado sem particionamento**
   - 100+ mensagens/dia por tenant
   - 36k+ mensagens/ano por tenant
   - 100 tenants = 3.6M mensagens/ano

2. ‚ùå **Falta de √≠ndice para conversa√ß√£o**
   ```sql
   -- Query comum:
   SELECT * FROM whatsapp_messages
   WHERE conversation_id = 'xxx'
   ORDER BY created_at DESC
   LIMIT 50;
   ```

3. ‚ùå **Campos de timestamp sem √≠ndice composto**

**Indexes Atuais:**
```sql
-- ‚ö†Ô∏è INSUFICIENTE para volume esperado
```

**Melhorias URGENTES:**

```sql
-- 1. PARTICIONAMENTO MENSAL (CR√çTICO)
ALTER TABLE whatsapp_messages
  RENAME TO whatsapp_messages_old;

CREATE TABLE whatsapp_messages (
  id varchar PRIMARY KEY,
  tenant_id varchar NOT NULL,
  conversation_id varchar NOT NULL,
  -- ... outros campos
  created_at timestamp NOT NULL DEFAULT NOW()
) PARTITION BY RANGE (created_at);

-- Parti√ß√µes mensais
CREATE TABLE whatsapp_messages_2024_12 PARTITION OF whatsapp_messages
  FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');

-- Migrar dados
INSERT INTO whatsapp_messages SELECT * FROM whatsapp_messages_old;
DROP TABLE whatsapp_messages_old;

-- 2. √çndices cr√≠ticos
CREATE INDEX idx_whatsapp_messages_conversation_created
  ON whatsapp_messages (conversation_id, created_at DESC);

CREATE INDEX idx_whatsapp_messages_tenant_created
  ON whatsapp_messages (tenant_id, created_at DESC);

CREATE INDEX idx_whatsapp_messages_status_created
  ON whatsapp_messages (status, created_at)
  WHERE status IN ('pending', 'failed');

-- 3. Cleanup autom√°tico (mensagens antigas)
CREATE OR REPLACE FUNCTION cleanup_old_whatsapp_messages()
RETURNS void AS $$
BEGIN
  -- Deletar mensagens > 6 meses (ap√≥s backup)
  DELETE FROM whatsapp_messages
  WHERE created_at < NOW() - INTERVAL '6 months'
    AND status NOT IN ('failed', 'pending');
END;
$$ LANGUAGE plpgsql;
```

**Prioridade:** üî¥ CR√çTICA
**Estimativa:** 6 horas

---

### Tabela: `files`

**Status:** üü° ATEN√á√ÉO

**Problemas Identificados:**

1. ‚ùå **Metadata JSON sem √≠ndice**
2. ‚ùå **Falta de constraint de tamanho m√°ximo**
3. ‚ùå **Sem valida√ß√£o de mime_type**

**Melhorias:**

```sql
-- 1. √çndice GIN para metadata
CREATE INDEX idx_files_metadata_gin ON files USING GIN (metadata);

-- 2. Constraint de tamanho
ALTER TABLE files
ADD CONSTRAINT check_file_size_limit
CHECK (size <= 104857600); -- 100MB max

-- 3. Valida√ß√£o de MIME types permitidos
ALTER TABLE files
ADD CONSTRAINT check_mime_type_allowed
CHECK (
  mime_type IN (
    'image/jpeg', 'image/png', 'image/webp',
    'application/pdf',
    'application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'video/mp4'
  )
);

-- 4. √çndice para busca por categoria e tipo
CREATE INDEX idx_files_category_entity
  ON files (category, entity_type, entity_id)
  WHERE deleted_at IS NULL;
```

---

## 4. INDEXES FALTANTES CR√çTICOS

### Prioridade ALTA üî¥

```sql
-- 1. GIN indexes para arrays (PostgreSQL)
CREATE INDEX idx_properties_features_gin ON properties USING GIN (features);
CREATE INDEX idx_properties_images_gin ON properties USING GIN (images);
CREATE INDEX idx_leads_interests_gin ON leads USING GIN (interests);

-- 2. √çndices para JSON
CREATE INDEX idx_user_roles_permissions_gin ON user_roles USING GIN (permissions);
CREATE INDEX idx_integration_configs_config_gin ON integration_configs USING GIN (config);
CREATE INDEX idx_files_metadata_gin ON files USING GIN (metadata);
CREATE INDEX idx_whatsapp_templates_buttons_gin ON whatsapp_templates USING GIN (buttons);

-- 3. Full-text search
CREATE INDEX idx_properties_search_vector ON properties USING GIN (search_vector);
CREATE INDEX idx_leads_search_vector ON leads USING GIN (
  to_tsvector('portuguese', coalesce(name, '') || ' ' || coalesce(email, ''))
);

-- 4. Geolocaliza√ß√£o (se usar PostGIS)
CREATE INDEX idx_properties_location ON properties
  USING GIST (ll_to_earth(latitude, longitude));

-- 5. √çndices compostos para queries comuns
CREATE INDEX idx_visits_tenant_scheduled_status
  ON visits (tenant_id, scheduled_for, status)
  WHERE deleted_at IS NULL;

CREATE INDEX idx_contracts_tenant_property_status
  ON contracts (tenant_id, property_id, status)
  WHERE deleted_at IS NULL;

CREATE INDEX idx_commissions_tenant_broker_status
  ON commissions (tenant_id, broker_id, status)
  WHERE deleted_at IS NULL AND status != 'paid';
```

### Prioridade M√âDIA üü°

```sql
-- 6. √çndices para dashboards
CREATE INDEX idx_finance_entries_tenant_date_flow
  ON finance_entries (tenant_id, entry_date DESC, flow)
  WHERE deleted_at IS NULL;

CREATE INDEX idx_follow_ups_tenant_due_status
  ON follow_ups (tenant_id, due_at, status)
  WHERE deleted_at IS NULL AND status != 'completed';

-- 7. √çndices para relat√≥rios
CREATE INDEX idx_property_sales_tenant_date
  ON property_sales (tenant_id, sale_date DESC)
  WHERE deleted_at IS NULL;

CREATE INDEX idx_rental_transfers_tenant_status_month
  ON rental_transfers (tenant_id, status, reference_month)
  WHERE deleted_at IS NULL;
```

---

## 5. PROBLEMAS DE NORMALIZA√á√ÉO

### 5.1 Campos Denormalizados (Aceit√°vel para Performance)

‚úÖ **Aceit√°vel:**
- `rental_payments.rent_value` (copiado de `rental_contracts.rent_value`)
- `commissions.transaction_value` (snapshot do valor na data)
- `property_sales.commission_value` (calculado, mas armazenado)

**Justificativa:** Dados hist√≥ricos que n√£o devem mudar mesmo se a origem mudar.

### 5.2 Dados Redundantes (Problemas)

‚ùå **Problema:**

```sql
-- Endere√ßos duplicados em m√∫ltiplas tabelas
properties: address, city, state, zip_code
owners: address
renters: address
tenants: address

-- Solu√ß√£o: Criar tabela de endere√ßos
CREATE TABLE addresses (
  id varchar PRIMARY KEY,
  street text NOT NULL,
  number text,
  complement text,
  neighborhood text,
  city_id varchar REFERENCES cities(id),
  zip_code text,
  latitude decimal(10,8),
  longitude decimal(11,8),
  created_at timestamp DEFAULT NOW()
);

CREATE TABLE cities (
  id varchar PRIMARY KEY,
  name text NOT NULL,
  state_code char(2) NOT NULL,
  country_code char(2) DEFAULT 'BR',
  timezone text DEFAULT 'America/Sao_Paulo'
);

-- Alterar tabelas para usar FK
ALTER TABLE properties ADD COLUMN address_id varchar REFERENCES addresses(id);
ALTER TABLE owners ADD COLUMN address_id varchar REFERENCES addresses(id);
```

### 5.3 Valores Enum n√£o Normalizados

‚ùå **Problema:**
```sql
-- Valores hardcoded em CHECK constraints
status IN ('available', 'sold', 'rented', 'unavailable', 'pending')
```

‚ö†Ô∏è **Aceit√°vel para simplicidade**, mas considerar:

```sql
-- Alternativa: Tabela de status
CREATE TABLE property_statuses (
  id varchar PRIMARY KEY,
  name text NOT NULL,
  category text NOT NULL, -- sale, rental, internal
  is_active boolean DEFAULT true,
  sort_order integer DEFAULT 0
);

-- Popullar
INSERT INTO property_statuses (id, name, category) VALUES
  ('available', 'Dispon√≠vel', 'sale'),
  ('sold', 'Vendido', 'sale'),
  ('rented', 'Alugado', 'rental');

-- FK na tabela
ALTER TABLE properties
  ADD CONSTRAINT fk_status
  FOREIGN KEY (status)
  REFERENCES property_statuses(id);
```

---

## 6. QUERIES LENTAS POTENCIAIS

### 6.1 Dashboard Principal

**Query Problem√°tica:**
```sql
SELECT
  (SELECT COUNT(*) FROM properties WHERE tenant_id = $1 AND deleted_at IS NULL) as total_properties,
  (SELECT COUNT(*) FROM properties WHERE tenant_id = $1 AND status = 'available' AND deleted_at IS NULL) as available,
  (SELECT COUNT(*) FROM leads WHERE tenant_id = $1 AND deleted_at IS NULL) as total_leads,
  (SELECT COUNT(*) FROM leads WHERE tenant_id = $1 AND status = 'new' AND deleted_at IS NULL) as new_leads,
  (SELECT COUNT(*) FROM contracts WHERE tenant_id = $1 AND status = 'active' AND deleted_at IS NULL) as active_contracts;
```

**Problema:** 5 queries separadas, cada uma full scan.

**Solu√ß√£o 1 - Materialized View:**
```sql
CREATE MATERIALIZED VIEW dashboard_stats_mv AS
SELECT
  tenant_id,
  COUNT(*) FILTER (WHERE entity_type = 'property') as total_properties,
  COUNT(*) FILTER (WHERE entity_type = 'property' AND status = 'available') as available_properties,
  COUNT(*) FILTER (WHERE entity_type = 'lead') as total_leads,
  COUNT(*) FILTER (WHERE entity_type = 'lead' AND status = 'new') as new_leads,
  COUNT(*) FILTER (WHERE entity_type = 'contract' AND status = 'active') as active_contracts,
  MAX(updated_at) as last_update
FROM (
  SELECT tenant_id, 'property' as entity_type, status, NOW() as updated_at FROM properties WHERE deleted_at IS NULL
  UNION ALL
  SELECT tenant_id, 'lead', status, NOW() FROM leads WHERE deleted_at IS NULL
  UNION ALL
  SELECT tenant_id, 'contract', status, NOW() FROM contracts WHERE deleted_at IS NULL
) combined
GROUP BY tenant_id;

-- Refresh a cada 1 minuto
```

**Solu√ß√£o 2 - Counters Table:**
```sql
CREATE TABLE entity_counters (
  tenant_id varchar NOT NULL,
  entity_type text NOT NULL,
  counter_type text NOT NULL,
  count integer NOT NULL DEFAULT 0,
  updated_at timestamp NOT NULL DEFAULT NOW(),
  PRIMARY KEY (tenant_id, entity_type, counter_type)
);

-- Triggers para incrementar/decrementar
CREATE OR REPLACE FUNCTION update_entity_counters()
RETURNS TRIGGER AS $$
BEGIN
  IF TG_OP = 'INSERT' THEN
    INSERT INTO entity_counters (tenant_id, entity_type, counter_type, count)
    VALUES (NEW.tenant_id, TG_TABLE_NAME, NEW.status, 1)
    ON CONFLICT (tenant_id, entity_type, counter_type)
    DO UPDATE SET count = entity_counters.count + 1, updated_at = NOW();
  ELSIF TG_OP = 'DELETE' THEN
    -- Decrementar
  ELSIF TG_OP = 'UPDATE' THEN
    -- Atualizar
  END IF;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;
```

### 6.2 Busca de Propriedades com Filtros

**Query Problem√°tica:**
```sql
SELECT * FROM properties
WHERE tenant_id = $1
  AND city = $2
  AND bedrooms >= $3
  AND price BETWEEN $4 AND $5
  AND status = 'available'
  AND 'piscina' = ANY(features)
  AND deleted_at IS NULL
ORDER BY created_at DESC
LIMIT 20;
```

**Problema:**
- M√∫ltiplos filtros sem √≠ndice composto ideal
- Array search sem √≠ndice GIN

**Solu√ß√£o:**
```sql
-- √çndice composto covering
CREATE INDEX idx_properties_search_optimized
  ON properties (tenant_id, city, status, bedrooms, price, created_at)
  WHERE deleted_at IS NULL;

-- √çndice GIN para features
CREATE INDEX idx_properties_features_gin
  ON properties USING GIN (features);

-- Query otimizada usando CTEs
WITH filtered_properties AS (
  SELECT *
  FROM properties
  WHERE tenant_id = $1
    AND city = $2
    AND bedrooms >= $3
    AND price BETWEEN $4 AND $5
    AND status = 'available'
    AND deleted_at IS NULL
),
with_features AS (
  SELECT *
  FROM filtered_properties
  WHERE 'piscina' = ANY(features)
)
SELECT * FROM with_features
ORDER BY created_at DESC
LIMIT 20;
```

### 6.3 Relat√≥rio Financeiro Mensal

**Query Problem√°tica:**
```sql
SELECT
  date_trunc('month', entry_date) as month,
  SUM(CASE WHEN flow = 'income' THEN amount ELSE 0 END) as income,
  SUM(CASE WHEN flow = 'expense' THEN amount ELSE 0 END) as expense
FROM finance_entries
WHERE tenant_id = $1
  AND entry_date BETWEEN $2 AND $3
  AND deleted_at IS NULL
GROUP BY date_trunc('month', entry_date)
ORDER BY month DESC;
```

**Problema:** Agrega√ß√£o em toda a tabela a cada requisi√ß√£o.

**Solu√ß√£o:**
```sql
-- Materialized view para relat√≥rios mensais
CREATE MATERIALIZED VIEW finance_monthly_summary_mv AS
SELECT
  tenant_id,
  date_trunc('month', entry_date) as month,
  SUM(amount) FILTER (WHERE flow = 'income') as total_income,
  SUM(amount) FILTER (WHERE flow = 'expense') as total_expense,
  SUM(amount) FILTER (WHERE flow = 'income') - SUM(amount) FILTER (WHERE flow = 'expense') as net_balance,
  COUNT(*) as entry_count
FROM finance_entries
WHERE deleted_at IS NULL
GROUP BY tenant_id, date_trunc('month', entry_date);

CREATE UNIQUE INDEX idx_finance_monthly_summary_tenant_month
  ON finance_monthly_summary_mv (tenant_id, month);

-- Refresh autom√°tico di√°rio
SELECT cron.schedule('refresh-finance-summary', '0 1 * * *',
  'REFRESH MATERIALIZED VIEW CONCURRENTLY finance_monthly_summary_mv');
```

---

## 7. MELHORIAS DE PERFORMANCE

### 7.1 Estrat√©gia de Caching

```sql
-- 1. Materialized Views para dados agregados (j√° mencionado)

-- 2. Tabela de cache com TTL
CREATE TABLE query_cache (
  cache_key varchar PRIMARY KEY,
  cache_value jsonb NOT NULL,
  expires_at timestamp NOT NULL,
  created_at timestamp NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_query_cache_expires ON query_cache (expires_at);

-- Cleanup autom√°tico
CREATE OR REPLACE FUNCTION cleanup_expired_cache()
RETURNS void AS $$
BEGIN
  DELETE FROM query_cache WHERE expires_at < NOW();
END;
$$ LANGUAGE plpgsql;

-- 3. PostgreSQL built-in caching
-- Shared buffers: 25% of RAM
-- effective_cache_size: 75% of RAM
-- work_mem: 4-16MB per connection
```

### 7.2 Connection Pooling

```javascript
// PgBouncer configuration
[databases]
imobibase = host=localhost port=5432 dbname=imobibase

[pgbouncer]
pool_mode = transaction
max_client_conn = 1000
default_pool_size = 25
reserve_pool_size = 5
reserve_pool_timeout = 5
```

### 7.3 Query Optimization Checklist

- [ ] Todas as queries usam √≠ndices (EXPLAIN ANALYZE)
- [ ] Joins usam √≠ndices em ambas as colunas
- [ ] WHERE clauses seguem a ordem dos √≠ndices compostos
- [ ] LIMIT usado para pagina√ß√£o
- [ ] COUNT(*) evitado (usar estimativas quando poss√≠vel)
- [ ] Subqueries substitu√≠das por JOINs quando poss√≠vel
- [ ] Agrega√ß√µes pr√©-calculadas em MV quando apropriado

---

## 8. SCRIPTS SQL DE CORRE√á√ÉO

### Script 1: Adicionar Particionamento (CR√çTICO)

**Arquivo:** `migrations/005_add_partitioning.sql`

```sql
-- ================================================================
-- MIGRATION 005: Add Partitioning to High-Volume Tables
-- Priority: üî¥ CRITICAL
-- Estimated Time: 2 hours
-- Downtime: ~5 minutes (during table rename)
-- ================================================================

BEGIN;

-- ============== AUDIT_LOGS PARTITIONING ==============

-- Step 1: Rename existing table
ALTER TABLE audit_logs RENAME TO audit_logs_old;

-- Step 2: Create partitioned table
CREATE TABLE audit_logs (
  id varchar PRIMARY KEY,
  tenant_id varchar NOT NULL REFERENCES tenants(id),
  user_id varchar REFERENCES users(id),
  action text NOT NULL,
  entity_type text NOT NULL,
  entity_id varchar,
  old_values text,
  new_values text,
  ip_address text,
  user_agent text,
  metadata text,
  created_at timestamp NOT NULL DEFAULT NOW()
) PARTITION BY RANGE (created_at);

-- Step 3: Create partitions (last 6 months + future 6 months)
CREATE TABLE audit_logs_2024_07 PARTITION OF audit_logs
  FOR VALUES FROM ('2024-07-01') TO ('2024-08-01');

CREATE TABLE audit_logs_2024_08 PARTITION OF audit_logs
  FOR VALUES FROM ('2024-08-01') TO ('2024-09-01');

CREATE TABLE audit_logs_2024_09 PARTITION OF audit_logs
  FOR VALUES FROM ('2024-09-01') TO ('2024-10-01');

CREATE TABLE audit_logs_2024_10 PARTITION OF audit_logs
  FOR VALUES FROM ('2024-10-01') TO ('2024-11-01');

CREATE TABLE audit_logs_2024_11 PARTITION OF audit_logs
  FOR VALUES FROM ('2024-11-01') TO ('2024-12-01');

CREATE TABLE audit_logs_2024_12 PARTITION OF audit_logs
  FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');

CREATE TABLE audit_logs_2025_01 PARTITION OF audit_logs
  FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE audit_logs_2025_02 PARTITION OF audit_logs
  FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

CREATE TABLE audit_logs_2025_03 PARTITION OF audit_logs
  FOR VALUES FROM ('2025-03-01') TO ('2025-04-01');

CREATE TABLE audit_logs_2025_04 PARTITION OF audit_logs
  FOR VALUES FROM ('2025-04-01') TO ('2025-05-01');

CREATE TABLE audit_logs_2025_05 PARTITION OF audit_logs
  FOR VALUES FROM ('2025-05-01') TO ('2025-06-01');

CREATE TABLE audit_logs_2025_06 PARTITION OF audit_logs
  FOR VALUES FROM ('2025-06-01') TO ('2025-07-01');

-- Step 4: Migrate existing data
INSERT INTO audit_logs SELECT * FROM audit_logs_old;

-- Step 5: Drop old table
DROP TABLE audit_logs_old;

-- Step 6: Re-create indexes on each partition (automatic)
-- Indexes are inherited from parent table

-- Step 7: Create function to auto-create partitions
CREATE OR REPLACE FUNCTION create_audit_log_partition()
RETURNS void AS $$
DECLARE
  start_date DATE;
  end_date DATE;
  partition_name TEXT;
BEGIN
  -- Create partition for next month
  start_date := date_trunc('month', NOW() + INTERVAL '1 month');
  end_date := start_date + INTERVAL '1 month';
  partition_name := 'audit_logs_' || to_char(start_date, 'YYYY_MM');

  EXECUTE format(
    'CREATE TABLE IF NOT EXISTS %I PARTITION OF audit_logs FOR VALUES FROM (%L) TO (%L)',
    partition_name, start_date, end_date
  );

  RAISE NOTICE 'Created partition: %', partition_name;
END;
$$ LANGUAGE plpgsql;

-- Step 8: Schedule monthly partition creation
SELECT cron.schedule(
  'create-audit-partitions',
  '0 0 25 * *', -- Run on 25th of each month
  'SELECT create_audit_log_partition()'
);

COMMIT;

-- ============== WHATSAPP_MESSAGES PARTITIONING ==============

BEGIN;

ALTER TABLE whatsapp_messages RENAME TO whatsapp_messages_old;

CREATE TABLE whatsapp_messages (
  id varchar PRIMARY KEY,
  tenant_id varchar NOT NULL REFERENCES tenants(id),
  conversation_id varchar NOT NULL REFERENCES whatsapp_conversations(id),
  waba_message_id text,
  direction text NOT NULL,
  message_type text NOT NULL DEFAULT 'text',
  content text,
  media_url text,
  caption text,
  template_id varchar REFERENCES whatsapp_templates(id),
  status text NOT NULL DEFAULT 'pending',
  error_code text,
  error_message text,
  sent_by varchar REFERENCES users(id),
  metadata json DEFAULT '{}',
  sent_at timestamp,
  delivered_at timestamp,
  read_at timestamp,
  created_at timestamp NOT NULL DEFAULT NOW()
) PARTITION BY RANGE (created_at);

-- Create partitions (3 months back + 3 months forward)
CREATE TABLE whatsapp_messages_2024_10 PARTITION OF whatsapp_messages
  FOR VALUES FROM ('2024-10-01') TO ('2024-11-01');

CREATE TABLE whatsapp_messages_2024_11 PARTITION OF whatsapp_messages
  FOR VALUES FROM ('2024-11-01') TO ('2024-12-01');

CREATE TABLE whatsapp_messages_2024_12 PARTITION OF whatsapp_messages
  FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');

CREATE TABLE whatsapp_messages_2025_01 PARTITION OF whatsapp_messages
  FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE whatsapp_messages_2025_02 PARTITION OF whatsapp_messages
  FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

CREATE TABLE whatsapp_messages_2025_03 PARTITION OF whatsapp_messages
  FOR VALUES FROM ('2025-03-01') TO ('2025-04-01');

-- Migrate data
INSERT INTO whatsapp_messages SELECT * FROM whatsapp_messages_old;

DROP TABLE whatsapp_messages_old;

-- Create indexes
CREATE INDEX idx_whatsapp_messages_conversation_created
  ON whatsapp_messages (conversation_id, created_at DESC);

CREATE INDEX idx_whatsapp_messages_tenant_created
  ON whatsapp_messages (tenant_id, created_at DESC);

COMMIT;

-- ================================================================
-- VERIFICATION
-- ================================================================

-- Check partition sizes
SELECT
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE tablename LIKE 'audit_logs_%' OR tablename LIKE 'whatsapp_messages_%'
ORDER BY tablename;

-- Test queries
EXPLAIN ANALYZE
SELECT * FROM audit_logs
WHERE created_at >= '2024-12-01'
  AND created_at < '2025-01-01'
LIMIT 100;

COMMENT ON TABLE audit_logs IS 'Partitioned by month for performance';
COMMENT ON TABLE whatsapp_messages IS 'Partitioned by month for performance';
```

---

### Script 2: Adicionar √çndices GIN/GiST (ALTA PRIORIDADE)

**Arquivo:** `migrations/006_add_gin_gist_indexes.sql`

```sql
-- ================================================================
-- MIGRATION 006: Add GIN and GiST Indexes
-- Priority: üî¥ HIGH
-- Estimated Time: 30 minutes
-- Downtime: None (indexes created CONCURRENTLY)
-- ================================================================

-- ============== GIN INDEXES FOR ARRAYS ==============

-- Properties: features and images arrays
CREATE INDEX CONCURRENTLY idx_properties_features_gin
  ON properties USING GIN (features);

CREATE INDEX CONCURRENTLY idx_properties_images_gin
  ON properties USING GIN (images);

-- Leads: interests array
CREATE INDEX CONCURRENTLY idx_leads_interests_gin
  ON leads USING GIN (interests);

-- WhatsApp Templates: variables and buttons
CREATE INDEX CONCURRENTLY idx_whatsapp_templates_variables_gin
  ON whatsapp_templates USING GIN (variables);

CREATE INDEX CONCURRENTLY idx_whatsapp_templates_buttons_gin
  ON whatsapp_templates USING GIN (buttons);

-- Notification Preferences: recipients array
CREATE INDEX CONCURRENTLY idx_notification_preferences_recipients_gin
  ON notification_preferences USING GIN (recipients);

-- ============== GIN INDEXES FOR JSON/JSONB ==============

-- User Roles: permissions JSON
CREATE INDEX CONCURRENTLY idx_user_roles_permissions_gin
  ON user_roles USING GIN (permissions::jsonb);

-- Integration Configs: config JSON
CREATE INDEX CONCURRENTLY idx_integration_configs_config_gin
  ON integration_configs USING GIN (config::jsonb);

-- Files: metadata JSON
CREATE INDEX CONCURRENTLY idx_files_metadata_gin
  ON files USING GIN (metadata::jsonb);

-- WhatsApp Messages: metadata JSON
CREATE INDEX CONCURRENTLY idx_whatsapp_messages_metadata_gin
  ON whatsapp_messages USING GIN (metadata::jsonb);

-- User Permissions: custom_permissions JSON
CREATE INDEX CONCURRENTLY idx_user_permissions_custom_gin
  ON user_permissions USING GIN (custom_permissions::jsonb);

-- Saved Reports: filters JSON
CREATE INDEX CONCURRENTLY idx_saved_reports_filters_gin
  ON saved_reports USING GIN (filters::jsonb);

-- Tenant Subscriptions: metadata JSON
CREATE INDEX CONCURRENTLY idx_tenant_subscriptions_metadata_gin
  ON tenant_subscriptions USING GIN (metadata::jsonb);

-- ============== FULL-TEXT SEARCH (TSVECTOR) ==============

-- Properties: Add search vector column
ALTER TABLE properties
ADD COLUMN IF NOT EXISTS search_vector tsvector
GENERATED ALWAYS AS (
  to_tsvector('portuguese',
    coalesce(title, '') || ' ' ||
    coalesce(description, '') || ' ' ||
    coalesce(address, '') || ' ' ||
    coalesce(city, '') || ' ' ||
    coalesce(state, '')
  )
) STORED;

CREATE INDEX CONCURRENTLY idx_properties_search_vector
  ON properties USING GIN (search_vector);

-- Leads: Add search vector column
ALTER TABLE leads
ADD COLUMN IF NOT EXISTS search_vector tsvector
GENERATED ALWAYS AS (
  to_tsvector('portuguese',
    coalesce(name, '') || ' ' ||
    coalesce(email, '') || ' ' ||
    coalesce(phone, '') || ' ' ||
    coalesce(notes, '')
  )
) STORED;

CREATE INDEX CONCURRENTLY idx_leads_search_vector
  ON leads USING GIN (search_vector);

-- Owners: Add search vector column
ALTER TABLE owners
ADD COLUMN IF NOT EXISTS search_vector tsvector
GENERATED ALWAYS AS (
  to_tsvector('portuguese',
    coalesce(name, '') || ' ' ||
    coalesce(email, '') || ' ' ||
    coalesce(phone, '') || ' ' ||
    coalesce(cpf_cnpj, '')
  )
) STORED;

CREATE INDEX CONCURRENTLY idx_owners_search_vector
  ON owners USING GIN (search_vector);

-- Renters: Add search vector column
ALTER TABLE renters
ADD COLUMN IF NOT EXISTS search_vector tsvector
GENERATED ALWAYS AS (
  to_tsvector('portuguese',
    coalesce(name, '') || ' ' ||
    coalesce(email, '') || ' ' ||
    coalesce(phone, '') || ' ' ||
    coalesce(cpf_cnpj, '')
  )
) STORED;

CREATE INDEX CONCURRENTLY idx_renters_search_vector
  ON renters USING GIN (search_vector);

-- ============== GiST INDEX FOR GEOLOCATION ==============
-- Note: Requires PostGIS extension

-- Enable PostGIS (if not already enabled)
CREATE EXTENSION IF NOT EXISTS postgis;

-- Add geography column to properties
ALTER TABLE properties
ADD COLUMN IF NOT EXISTS location geography(POINT, 4326);

-- Update existing properties with coordinates
UPDATE properties p
SET location = ST_SetSRID(ST_MakePoint(pc.longitude, pc.latitude), 4326)::geography
FROM property_coordinates pc
WHERE p.id = pc.property_id
  AND p.location IS NULL;

-- Create GiST index for spatial queries
CREATE INDEX CONCURRENTLY idx_properties_location_gist
  ON properties USING GIST (location);

-- ================================================================
-- USAGE EXAMPLES
-- ================================================================

/*
-- 1. Array search (features)
SELECT * FROM properties
WHERE features @> ARRAY['piscina', 'churrasqueira']::text[]
  AND tenant_id = 'xxx'
  AND deleted_at IS NULL;

-- 2. JSON search (permissions)
SELECT * FROM user_roles
WHERE permissions::jsonb @> '{"properties": {"create": true}}'::jsonb;

-- 3. Full-text search (properties)
SELECT * FROM properties
WHERE search_vector @@ to_tsquery('portuguese', 'apartamento & sacada')
  AND tenant_id = 'xxx'
  AND deleted_at IS NULL
ORDER BY ts_rank(search_vector, to_tsquery('portuguese', 'apartamento & sacada')) DESC;

-- 4. Geolocation search (properties within 5km radius)
SELECT
  id,
  title,
  ST_Distance(location, ST_SetSRID(ST_MakePoint(-46.6333, -23.5505), 4326)::geography) / 1000 AS distance_km
FROM properties
WHERE ST_DWithin(
    location,
    ST_SetSRID(ST_MakePoint(-46.6333, -23.5505), 4326)::geography,
    5000 -- 5km in meters
  )
  AND tenant_id = 'xxx'
  AND deleted_at IS NULL
ORDER BY distance_km;
*/

-- ================================================================
-- VERIFICATION
-- ================================================================

-- Check index sizes
SELECT
  schemaname,
  tablename,
  indexname,
  pg_size_pretty(pg_relation_size(indexname::regclass)) AS index_size
FROM pg_indexes
WHERE indexname LIKE '%_gin' OR indexname LIKE '%_gist' OR indexname LIKE '%search_vector%'
ORDER BY pg_relation_size(indexname::regclass) DESC;

-- Test query performance
EXPLAIN ANALYZE
SELECT * FROM properties
WHERE search_vector @@ to_tsquery('portuguese', 'apartamento')
LIMIT 10;

COMMENT ON INDEX idx_properties_search_vector IS 'Full-text search for properties in Portuguese';
COMMENT ON INDEX idx_properties_features_gin IS 'Array search for property features';
COMMENT ON INDEX idx_properties_location_gist IS 'Geospatial search for properties';
```

---

### Script 3: Adicionar Materialized Views (M√âDIA PRIORIDADE)

**Arquivo:** `migrations/007_add_materialized_views.sql`

```sql
-- ================================================================
-- MIGRATION 007: Add Materialized Views for Analytics
-- Priority: üü° MEDIUM
-- Estimated Time: 1 hour
-- Downtime: None
-- ================================================================

-- ============== DASHBOARD METRICS ==============

CREATE MATERIALIZED VIEW dashboard_metrics_mv AS
SELECT
  p.tenant_id,
  -- Properties
  COUNT(DISTINCT p.id) as total_properties,
  COUNT(DISTINCT p.id) FILTER (WHERE p.status = 'available') as available_properties,
  COUNT(DISTINCT p.id) FILTER (WHERE p.status = 'rented') as rented_properties,
  COUNT(DISTINCT p.id) FILTER (WHERE p.status = 'sold') as sold_properties,
  COUNT(DISTINCT p.id) FILTER (WHERE p.featured = true) as featured_properties,
  -- Leads
  COUNT(DISTINCT l.id) as total_leads,
  COUNT(DISTINCT l.id) FILTER (WHERE l.status = 'new') as new_leads,
  COUNT(DISTINCT l.id) FILTER (WHERE l.status = 'qualified') as qualified_leads,
  COUNT(DISTINCT l.id) FILTER (WHERE l.status = 'won') as won_leads,
  -- Contracts
  COUNT(DISTINCT c.id) as total_contracts,
  COUNT(DISTINCT c.id) FILTER (WHERE c.status = 'active') as active_contracts,
  -- Rental Contracts
  COUNT(DISTINCT rc.id) as total_rental_contracts,
  COUNT(DISTINCT rc.id) FILTER (WHERE rc.status = 'active') as active_rentals,
  -- Visits
  COUNT(DISTINCT v.id) FILTER (WHERE v.scheduled_for >= CURRENT_DATE) as upcoming_visits,
  -- Follow Ups
  COUNT(DISTINCT f.id) FILTER (WHERE f.status = 'pending' AND f.due_at <= CURRENT_DATE + INTERVAL '7 days') as pending_followups,
  -- Last update
  NOW() as last_updated
FROM tenants t
LEFT JOIN properties p ON p.tenant_id = t.id AND p.deleted_at IS NULL
LEFT JOIN leads l ON l.tenant_id = t.id AND l.deleted_at IS NULL
LEFT JOIN contracts c ON c.tenant_id = t.id AND c.deleted_at IS NULL
LEFT JOIN rental_contracts rc ON rc.tenant_id = t.id AND rc.deleted_at IS NULL
LEFT JOIN visits v ON v.tenant_id = t.id AND v.deleted_at IS NULL
LEFT JOIN follow_ups f ON f.tenant_id = t.id AND f.deleted_at IS NULL
GROUP BY p.tenant_id;

CREATE UNIQUE INDEX idx_dashboard_metrics_mv_tenant
  ON dashboard_metrics_mv (tenant_id);

-- ============== FINANCIAL SUMMARY ==============

CREATE MATERIALIZED VIEW financial_monthly_summary_mv AS
SELECT
  tenant_id,
  date_trunc('month', entry_date) as month,
  SUM(amount::numeric) FILTER (WHERE flow = 'income') as total_income,
  SUM(amount::numeric) FILTER (WHERE flow = 'expense') as total_expense,
  SUM(amount::numeric) FILTER (WHERE flow = 'income') -
    SUM(amount::numeric) FILTER (WHERE flow = 'expense') as net_balance,
  COUNT(*) as total_entries,
  COUNT(*) FILTER (WHERE flow = 'income') as income_count,
  COUNT(*) FILTER (WHERE flow = 'expense') as expense_count,
  NOW() as last_updated
FROM finance_entries
WHERE deleted_at IS NULL
  AND status = 'completed'
GROUP BY tenant_id, date_trunc('month', entry_date);

CREATE UNIQUE INDEX idx_financial_monthly_summary_mv_tenant_month
  ON financial_monthly_summary_mv (tenant_id, month);

-- ============== RENTAL PAYMENTS SUMMARY ==============

CREATE MATERIALIZED VIEW rental_payments_summary_mv AS
SELECT
  tenant_id,
  date_trunc('month', due_date) as month,
  COUNT(*) as total_payments,
  COUNT(*) FILTER (WHERE status = 'paid') as paid_count,
  COUNT(*) FILTER (WHERE status = 'pending') as pending_count,
  COUNT(*) FILTER (WHERE status = 'overdue') as overdue_count,
  SUM(total_value::numeric) as total_amount,
  SUM(total_value::numeric) FILTER (WHERE status = 'paid') as paid_amount,
  SUM(total_value::numeric) FILTER (WHERE status = 'pending') as pending_amount,
  SUM(total_value::numeric) FILTER (WHERE status = 'overdue') as overdue_amount,
  AVG(total_value::numeric) as average_payment,
  NOW() as last_updated
FROM rental_payments
WHERE deleted_at IS NULL
GROUP BY tenant_id, date_trunc('month', due_date);

CREATE UNIQUE INDEX idx_rental_payments_summary_mv_tenant_month
  ON rental_payments_summary_mv (tenant_id, month);

-- ============== LEAD CONVERSION FUNNEL ==============

CREATE MATERIALIZED VIEW lead_conversion_funnel_mv AS
SELECT
  tenant_id,
  date_trunc('month', created_at) as month,
  COUNT(*) as total_leads,
  COUNT(*) FILTER (WHERE status = 'new') as new_count,
  COUNT(*) FILTER (WHERE status = 'contacted') as contacted_count,
  COUNT(*) FILTER (WHERE status = 'qualified') as qualified_count,
  COUNT(*) FILTER (WHERE status = 'negotiation') as negotiation_count,
  COUNT(*) FILTER (WHERE status = 'won') as won_count,
  COUNT(*) FILTER (WHERE status = 'lost') as lost_count,
  ROUND(100.0 * COUNT(*) FILTER (WHERE status = 'won') / NULLIF(COUNT(*), 0), 2) as conversion_rate,
  NOW() as last_updated
FROM leads
WHERE deleted_at IS NULL
GROUP BY tenant_id, date_trunc('month', created_at);

CREATE UNIQUE INDEX idx_lead_conversion_funnel_mv_tenant_month
  ON lead_conversion_funnel_mv (tenant_id, month);

-- ============== PROPERTY PERFORMANCE ==============

CREATE MATERIALIZED VIEW property_performance_mv AS
SELECT
  p.tenant_id,
  p.id as property_id,
  p.title,
  p.status,
  p.price,
  p.created_at,
  -- Visits
  COUNT(DISTINCT v.id) as total_visits,
  COUNT(DISTINCT v.id) FILTER (WHERE v.status = 'completed') as completed_visits,
  -- Proposals
  COUNT(DISTINCT sp.id) as total_proposals,
  COUNT(DISTINCT sp.id) FILTER (WHERE sp.status = 'accepted') as accepted_proposals,
  -- Time on market
  CASE
    WHEN p.status IN ('sold', 'rented') THEN EXTRACT(days FROM (p.updated_at - p.created_at))
    ELSE EXTRACT(days FROM (NOW() - p.created_at))
  END as days_on_market,
  NOW() as last_updated
FROM properties p
LEFT JOIN visits v ON v.property_id = p.id AND v.deleted_at IS NULL
LEFT JOIN sale_proposals sp ON sp.property_id = p.id AND sp.deleted_at IS NULL
WHERE p.deleted_at IS NULL
GROUP BY p.tenant_id, p.id, p.title, p.status, p.price, p.created_at, p.updated_at;

CREATE UNIQUE INDEX idx_property_performance_mv_property
  ON property_performance_mv (property_id);

CREATE INDEX idx_property_performance_mv_tenant
  ON property_performance_mv (tenant_id);

-- ============== BROKER PERFORMANCE ==============

CREATE MATERIALIZED VIEW broker_performance_mv AS
SELECT
  u.tenant_id,
  u.id as broker_id,
  u.name as broker_name,
  -- Leads
  COUNT(DISTINCT l.id) as assigned_leads,
  COUNT(DISTINCT l.id) FILTER (WHERE l.status = 'won') as converted_leads,
  -- Sales
  COUNT(DISTINCT ps.id) as total_sales,
  SUM(ps.sale_value::numeric) as total_sales_value,
  -- Rentals
  COUNT(DISTINCT rc.id) as total_rentals,
  SUM(rc.rent_value::numeric * 12) as annual_rental_value,
  -- Commissions
  COUNT(DISTINCT cm.id) as total_commissions,
  SUM(cm.broker_commission::numeric) FILTER (WHERE cm.status = 'paid') as paid_commissions,
  SUM(cm.broker_commission::numeric) FILTER (WHERE cm.status = 'pending') as pending_commissions,
  -- Conversion rate
  ROUND(100.0 * COUNT(DISTINCT l.id) FILTER (WHERE l.status = 'won') / NULLIF(COUNT(DISTINCT l.id), 0), 2) as conversion_rate,
  NOW() as last_updated
FROM users u
LEFT JOIN leads l ON l.assigned_to = u.id AND l.deleted_at IS NULL
LEFT JOIN property_sales ps ON ps.broker_id = u.id AND ps.deleted_at IS NULL
LEFT JOIN rental_contracts rc ON EXISTS (
  SELECT 1 FROM leads rl WHERE rl.id = rc.renter_id AND rl.assigned_to = u.id
)
LEFT JOIN commissions cm ON cm.broker_id = u.id AND cm.deleted_at IS NULL
WHERE u.role = 'broker' AND u.deleted_at IS NULL
GROUP BY u.tenant_id, u.id, u.name;

CREATE UNIQUE INDEX idx_broker_performance_mv_broker
  ON broker_performance_mv (broker_id);

CREATE INDEX idx_broker_performance_mv_tenant
  ON broker_performance_mv (tenant_id);

-- ================================================================
-- REFRESH FUNCTIONS
-- ================================================================

-- Refresh all materialized views
CREATE OR REPLACE FUNCTION refresh_all_materialized_views()
RETURNS void AS $$
BEGIN
  REFRESH MATERIALIZED VIEW CONCURRENTLY dashboard_metrics_mv;
  REFRESH MATERIALIZED VIEW CONCURRENTLY financial_monthly_summary_mv;
  REFRESH MATERIALIZED VIEW CONCURRENTLY rental_payments_summary_mv;
  REFRESH MATERIALIZED VIEW CONCURRENTLY lead_conversion_funnel_mv;
  REFRESH MATERIALIZED VIEW CONCURRENTLY property_performance_mv;
  REFRESH MATERIALIZED VIEW CONCURRENTLY broker_performance_mv;

  RAISE NOTICE 'All materialized views refreshed at %', NOW();
END;
$$ LANGUAGE plpgsql;

-- Schedule refresh every 5 minutes during business hours
SELECT cron.schedule(
  'refresh-materialized-views',
  '*/5 6-22 * * *', -- Every 5 minutes between 6 AM and 10 PM
  'SELECT refresh_all_materialized_views()'
);

-- Manual refresh during deployment
-- SELECT refresh_all_materialized_views();

-- ================================================================
-- USAGE EXAMPLES
-- ================================================================

/*
-- Dashboard query (FAST!)
SELECT * FROM dashboard_metrics_mv
WHERE tenant_id = 'tenant-123';

-- Financial report (INSTANT!)
SELECT * FROM financial_monthly_summary_mv
WHERE tenant_id = 'tenant-123'
  AND month >= date_trunc('month', NOW() - INTERVAL '6 months')
ORDER BY month DESC;

-- Broker leaderboard
SELECT * FROM broker_performance_mv
WHERE tenant_id = 'tenant-123'
ORDER BY total_sales_value DESC
LIMIT 10;
*/

-- ================================================================
-- VERIFICATION
-- ================================================================

-- Check MV sizes and data
SELECT
  schemaname,
  matviewname,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||matviewname)) AS size,
  (SELECT COUNT(*) FROM information_schema.tables WHERE table_name = matviewname) AS row_count
FROM pg_matviews
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||matviewname) DESC;

COMMENT ON MATERIALIZED VIEW dashboard_metrics_mv IS 'Pre-calculated dashboard metrics, refreshed every 5 minutes';
COMMENT ON MATERIALIZED VIEW financial_monthly_summary_mv IS 'Monthly financial summary, refreshed every 5 minutes';
COMMENT ON MATERIALIZED VIEW broker_performance_mv IS 'Broker performance metrics for leaderboard';
```

---

## 9. ROADMAP DE IMPLEMENTA√á√ÉO

### Fase 1: CR√çTICO (Semana 1)

**Prioridade:** üî¥ M√°xima
**Tempo Estimado:** 12 horas
**Downtime:** ~15 minutos total

- [ ] **Day 1-2:** Implementar particionamento
  - `audit_logs` (2h)
  - `compliance_audit_log` (1h)
  - `whatsapp_messages` (2h)
  - `usage_logs` (1h)
  - Testes e valida√ß√£o (1h)

- [ ] **Day 3:** Adicionar √≠ndices GIN/GiST
  - Arrays (30min)
  - JSON (30min)
  - Full-text search (1h)
  - Geolocation (1h)
  - Testes de performance (1h)

- [ ] **Day 4-5:** Backup e monitoring
  - Configurar backup autom√°tico (2h)
  - Setup monitoring (Prometheus + Grafana) (4h)

### Fase 2: ALTA (Semana 2-3)

**Prioridade:** üü° Alta
**Tempo Estimado:** 16 horas
**Downtime:** 0

- [ ] **Week 2:** Materialized Views
  - Dashboard metrics (2h)
  - Financial summaries (2h)
  - Broker performance (2h)
  - Refresh automation (2h)

- [ ] **Week 3:** Row-Level Security
  - Habilitar RLS (2h)
  - Criar policies (3h)
  - Testar isolamento (2h)
  - Documenta√ß√£o (1h)

### Fase 3: M√âDIO (Semana 4)

**Prioridade:** üü¢ M√©dia
**Tempo Estimado:** 8 horas
**Downtime:** 0

- [ ] Normaliza√ß√£o de endere√ßos
- [ ] Tabelas de enum para status
- [ ] Valida√ß√µes de email/phone
- [ ] Triggers de denormaliza√ß√£o

### Fase 4: OTIMIZA√á√ïES (Ongoing)

- [ ] Connection pooling (PgBouncer)
- [ ] Query optimization
- [ ] Cache estrat√©gico
- [ ] Monitoramento cont√≠nuo

---

## 10. M√âTRICAS DE SUCESSO

### Antes das Melhorias

| M√©trica | Valor Atual | Meta | Status |
|---------|-------------|------|--------|
| Dashboard load time | 2-5s | <500ms | üî¥ |
| Property search | 1-3s | <200ms | üî¥ |
| Audit log queries | 5-10s | <1s | üî¥ |
| Financial reports | 3-8s | <1s | üî¥ |
| WhatsApp message load | 2-4s | <300ms | üî¥ |
| Database size growth | Ilimitado | Controlado | üî¥ |

### Ap√≥s Melhorias Esperadas

| M√©trica | Valor Esperado | Melhoria | Status |
|---------|----------------|----------|--------|
| Dashboard load time | <300ms | 10x | üéØ |
| Property search | <100ms | 20x | üéØ |
| Audit log queries | <500ms | 20x | üéØ |
| Financial reports | <500ms | 16x | üéØ |
| WhatsApp message load | <150ms | 20x | üéØ |
| Database size growth | 30% redu√ß√£o | - | üéØ |

---

## 11. CONSIDERA√á√ïES FINAIS

### Pontos Fortes do Schema Atual ‚úÖ

1. **Excelente multi-tenancy** com tenant_id em todas as tabelas
2. **Soft deletes** implementados corretamente
3. **Audit trail** completo
4. **CHECK constraints** robustos
5. **CASCADE behaviors** bem definidos
6. **√çndices b√°sicos** bem estruturados
7. **LGPD/GDPR** compliance tables

### Pontos de Melhoria Priorit√°rios ‚ö†Ô∏è

1. **Particionamento** para tabelas de alto volume
2. **Full-text search** para melhor UX
3. **Materialized views** para analytics
4. **Row-level security** para seguran√ßa extra
5. **JSON validation** e √≠ndices GIN
6. **Geolocation** otimizada com PostGIS

### Risco de N√£o Implementar üö®

- **Performance degradation** com crescimento de dados
- **Custos de infraestrutura** aumentados (servidor maior necess√°rio)
- **UX ruim** com queries lentas
- **Dificuldade de escalabilidade**
- **Poss√≠vel vazamento de dados** sem RLS

### ROI Estimado üí∞

**Investimento:**
- Tempo de desenvolvimento: ~40 horas
- Tempo de QA/Testes: ~10 horas
- Total: ~50 horas (~1.5 semanas)

**Retorno:**
- Performance: 10-20x melhoria
- Custos de servidor: -30% (melhor uso de recursos)
- UX: 5x melhor (tempos de resposta)
- Escalabilidade: Suporta 10x mais dados sem degrada√ß√£o

---

## ANEXOS

### Anexo A: Queries de Monitoramento

```sql
-- 1. Verificar tamanho de tabelas e √≠ndices
SELECT
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
  pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
  pg_size_pretty(pg_indexes_size(schemaname||'.'||tablename)) AS indexes_size,
  (SELECT COUNT(*) FROM information_schema.tables t WHERE t.table_name = tablename) AS approx_rows
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
LIMIT 20;

-- 2. Queries lentas (requer pg_stat_statements)
SELECT
  calls,
  total_exec_time::numeric(10,2) as total_time_ms,
  mean_exec_time::numeric(10,2) as mean_time_ms,
  stddev_exec_time::numeric(10,2) as stddev_time_ms,
  query
FROM pg_stat_statements
WHERE query NOT LIKE '%pg_%'
ORDER BY mean_exec_time DESC
LIMIT 20;

-- 3. √çndices n√£o utilizados
SELECT
  schemaname,
  tablename,
  indexname,
  idx_scan,
  pg_size_pretty(pg_relation_size(indexname::regclass)) AS index_size
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
  AND idx_scan = 0
  AND indexname NOT LIKE '%_pkey'
ORDER BY pg_relation_size(indexname::regclass) DESC;

-- 4. Bloat de tabelas (estimativa)
SELECT
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
  n_tup_ins,
  n_tup_upd,
  n_tup_del,
  last_vacuum,
  last_autovacuum
FROM pg_stat_user_tables
WHERE schemaname = 'public'
ORDER BY n_tup_upd + n_tup_del DESC
LIMIT 20;

-- 5. Conex√µes ativas
SELECT
  datname,
  count(*) as connections,
  max(state) as state
FROM pg_stat_activity
WHERE datname IS NOT NULL
GROUP BY datname
ORDER BY connections DESC;
```

### Anexo B: Configura√ß√µes Recomendadas (postgresql.conf)

```ini
# MEMORY
shared_buffers = 4GB                    # 25% of RAM
effective_cache_size = 12GB             # 75% of RAM
work_mem = 16MB                         # Per connection
maintenance_work_mem = 512MB            # For VACUUM, CREATE INDEX

# CHECKPOINT
checkpoint_completion_target = 0.9
wal_buffers = 16MB
max_wal_size = 4GB
min_wal_size = 1GB

# QUERY PLANNER
random_page_cost = 1.1                  # SSD
effective_io_concurrency = 200          # SSD

# PARALLEL QUERY
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
max_worker_processes = 8

# LOGGING
log_min_duration_statement = 1000       # Log queries > 1s
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on

# STATISTICS
shared_preload_libraries = 'pg_stat_statements'
pg_stat_statements.max = 10000
pg_stat_statements.track = all
```

---

**Fim do Relat√≥rio**

**Pr√≥ximos Passos:**
1. Review deste relat√≥rio com time t√©cnico
2. Prioriza√ß√£o das melhorias
3. Cria√ß√£o de tasks no projeto
4. In√≠cio da implementa√ß√£o em Fase 1

**Contato:**
Para d√∫vidas ou sugest√µes sobre este relat√≥rio, consulte a documenta√ß√£o t√©cnica ou abra uma issue no reposit√≥rio.
